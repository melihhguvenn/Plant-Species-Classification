{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1s4BmdsvGumHcJNo_J7tZrj1RgN_8e38v",
      "authorship_tag": "ABX9TyPzUuGXuajb5X14YCqe++pv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/melihhguvenn/Plant-Species-Classification/blob/main/code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set dataset folder path from google drive and set processed dataset folder on drive, define splitted paths and create if those do not exist"
      ],
      "metadata": {
        "id": "EpMNvR8v-a4z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLr584402v1k"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "DATASET_PATH = Path(\"/content/drive/MyDrive/dataset\")\n",
        "SPLIT_DATASET_PATH = Path(\"/content/drive/MyDrive/split_dataset\")\n",
        "\n",
        "TRAIN_PATH = SPLIT_DATASET_PATH / \"train\"\n",
        "VAL_PATH = SPLIT_DATASET_PATH / \"val\"\n",
        "TEST_PATH = SPLIT_DATASET_PATH / \"test\"\n",
        "\n",
        "os.makedirs(TRAIN_PATH, exist_ok=True)\n",
        "os.makedirs(VAL_PATH, exist_ok=True)\n",
        "os.makedirs(TEST_PATH, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract image paths and labels. Then create data frame for easier manipulation of images"
      ],
      "metadata": {
        "id": "xx4xgr-Z-wj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMAGE_PATH_LIST = list(DATASET_PATH.glob(\"*/*.jpg\"))\n",
        "images_path = [img_path for img_path in IMAGE_PATH_LIST]\n",
        "labels = [img_path.parent.stem for img_path in IMAGE_PATH_LIST]\n",
        "\n",
        "dataset_df = pd.DataFrame({'image_path': images_path, 'label': labels})"
      ],
      "metadata": {
        "id": "3zFd522q97bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset splitted into 80 10 10"
      ],
      "metadata": {
        "id": "y2FH6hMU-6Pa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, temp_df = train_test_split(\n",
        "    dataset_df,\n",
        "    test_size=0.2,\n",
        "    stratify=dataset_df['label'],\n",
        "    random_state=42\n",
        ")\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.5,\n",
        "    stratify=temp_df['label'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Total Images: {len(dataset_df)}\")\n",
        "print(f\"Training Set: {len(train_df)} images\")\n",
        "print(f\"Validation Set: {len(val_df)} images\")\n",
        "print(f\"Test Set: {len(test_df)} images\")"
      ],
      "metadata": {
        "id": "1SvlRZzt9OAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create directory structure using labels"
      ],
      "metadata": {
        "id": "cwQoUqsH-_NP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dir_structure(base_path, labels):\n",
        "    for label in labels:\n",
        "        os.makedirs(base_path / label, exist_ok=True)\n",
        "\n",
        "unique_labels = dataset_df['label'].unique()\n",
        "create_dir_structure(TRAIN_PATH, unique_labels)\n",
        "create_dir_structure(VAL_PATH, unique_labels)\n",
        "create_dir_structure(TEST_PATH, unique_labels)"
      ],
      "metadata": {
        "id": "KJovS0Dx-OqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Copy images to directories"
      ],
      "metadata": {
        "id": "tJAAhrCs_FOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def copy_images(df, dest_dir):\n",
        "    for idx, row in df.iterrows():\n",
        "        src = str(row['image_path'])\n",
        "        dst = str(dest_dir / row['label'] / row['image_path'].name)\n",
        "        shutil.copy(src, dst)\n",
        "\n",
        "copy_images(train_df, TRAIN_PATH)\n",
        "copy_images(val_df, VAL_PATH)\n",
        "copy_images(test_df, TEST_PATH)"
      ],
      "metadata": {
        "id": "ksA7cSKF-RL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data augmentation to equalize class counts using resizing, shear, rotation, shifts, zoom, flip. Save with prefix aug_"
      ],
      "metadata": {
        "id": "vfjSbt2E_IHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = train_df['label'].value_counts()\n",
        "max_count = class_counts.max()\n",
        "image_size = 224\n",
        "\n",
        "for label, count in class_counts.items():\n",
        "    num_to_generate = max_count - count\n",
        "    if num_to_generate > 0:\n",
        "        print(f\"Augmenting {label}: {count} -> {max_count} images\")\n",
        "        datagen = ImageDataGenerator(\n",
        "            rotation_range=30,\n",
        "            width_shift_range=0.1,\n",
        "            height_shift_range=0.1,\n",
        "            shear_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            horizontal_flip=True,\n",
        "            fill_mode='nearest'\n",
        "        )\n",
        "        class_dir = TRAIN_PATH / label\n",
        "        class_images = [f for f in os.listdir(class_dir) if os.path.isfile(class_dir / f)]\n",
        "        df_aug = pd.DataFrame({'filename': class_images})\n",
        "        generator = datagen.flow_from_dataframe(\n",
        "            df_aug,\n",
        "            directory=str(class_dir),\n",
        "            x_col='filename',\n",
        "            y_col=None,\n",
        "            target_size=(image_size, image_size),\n",
        "            class_mode=None,\n",
        "            batch_size=1,\n",
        "            save_to_dir=str(class_dir),\n",
        "            save_prefix='aug_',\n",
        "            save_format='jpg',\n",
        "            shuffle=True\n",
        "        )\n",
        "        num_generated = 0\n",
        "        for _ in range(num_to_generate):\n",
        "            next(generator)\n",
        "            num_generated += 1\n",
        "            if num_generated >= num_to_generate:\n",
        "                break\n",
        "        print(f\"Generated {num_generated} images for class '{label}'.\")\n",
        "\n",
        "print(\"Data augmentation and oversampling completed.\")"
      ],
      "metadata": {
        "id": "RAFlHk61-WG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for class imbalance problem after augmentation"
      ],
      "metadata": {
        "id": "c9sZC6vD_en9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_class_counts = {label: len(os.listdir(TRAIN_PATH / label)) for label in unique_labels}\n",
        "print(\"Balanced Training Set Class Distribution:\")\n",
        "for label, count in balanced_class_counts.items():\n",
        "    print(f\"{label}: {count}\")"
      ],
      "metadata": {
        "id": "NYa9xE0O-Y0E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}